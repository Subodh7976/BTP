{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9364160,"sourceType":"datasetVersion","datasetId":5678141}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Data Ingestion","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# column_names = ['id', 'text', 'label']\ntwitter_train = pd.read_csv(\"/kaggle/input/dataset-3/train_formatted.csv\")\ntwitter_test = pd.read_csv(\"/kaggle/input/dataset-3/test_formatted.csv\")\ntwitter_dev = pd.read_csv(\"/kaggle/input/dataset-3/dev_formatted.csv\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-06T12:31:23.077663Z","iopub.execute_input":"2024-11-06T12:31:23.078638Z","iopub.status.idle":"2024-11-06T12:31:23.525851Z","shell.execute_reply.started":"2024-11-06T12:31:23.078583Z","shell.execute_reply":"2024-11-06T12:31:23.524807Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"twitter_train.shape, twitter_test.shape, twitter_dev.shape","metadata":{"execution":{"iopub.status.busy":"2024-11-06T12:31:23.776757Z","iopub.execute_input":"2024-11-06T12:31:23.777132Z","iopub.status.idle":"2024-11-06T12:31:23.785203Z","shell.execute_reply.started":"2024-11-06T12:31:23.777089Z","shell.execute_reply":"2024-11-06T12:31:23.784188Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"((1557, 5), (520, 5), (485, 5))"},"metadata":{}}]},{"cell_type":"markdown","source":"## Data Preparation","metadata":{}},{"cell_type":"code","source":"LABELS = twitter_train['label'].unique().tolist()\ntrain_label = twitter_train['label'].replace(LABELS, [0, 1, 2, 3]).tolist()","metadata":{"execution":{"iopub.status.busy":"2024-11-06T12:31:24.636305Z","iopub.execute_input":"2024-11-06T12:31:24.636679Z","iopub.status.idle":"2024-11-06T12:31:24.656527Z","shell.execute_reply.started":"2024-11-06T12:31:24.636643Z","shell.execute_reply":"2024-11-06T12:31:24.655363Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/3616623573.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  train_label = twitter_train['label'].replace(LABELS, [0, 1, 2, 3]).tolist()\n","output_type":"stream"}]},{"cell_type":"code","source":"train_data = twitter_train['text'].tolist()","metadata":{"execution":{"iopub.status.busy":"2024-11-06T12:31:24.996344Z","iopub.execute_input":"2024-11-06T12:31:24.997101Z","iopub.status.idle":"2024-11-06T12:31:25.001759Z","shell.execute_reply.started":"2024-11-06T12:31:24.997057Z","shell.execute_reply":"2024-11-06T12:31:25.000687Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"dev_data = twitter_dev['text'].tolist()\ndev_label = twitter_dev['label'].replace(LABELS, [0, 1, 2, 3]).tolist()","metadata":{"execution":{"iopub.status.busy":"2024-11-06T12:31:25.405992Z","iopub.execute_input":"2024-11-06T12:31:25.406394Z","iopub.status.idle":"2024-11-06T12:31:25.413613Z","shell.execute_reply.started":"2024-11-06T12:31:25.406356Z","shell.execute_reply":"2024-11-06T12:31:25.412647Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/3987848631.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  dev_label = twitter_dev['label'].replace(LABELS, [0, 1, 2, 3]).tolist()\n","output_type":"stream"}]},{"cell_type":"code","source":"test_data = twitter_test['text'].tolist()\ntest_label = twitter_test['label'].replace(LABELS, [0, 1, 2, 3]).tolist()","metadata":{"execution":{"iopub.status.busy":"2024-11-06T12:31:25.741953Z","iopub.execute_input":"2024-11-06T12:31:25.742339Z","iopub.status.idle":"2024-11-06T12:31:25.750337Z","shell.execute_reply.started":"2024-11-06T12:31:25.742302Z","shell.execute_reply":"2024-11-06T12:31:25.749324Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/2548705681.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  test_label = twitter_test['label'].replace(LABELS, [0, 1, 2, 3]).tolist()\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\n\nclass ClassificationDataset(Dataset):\n    def __init__(self, texts: list[str], labels: list[int], tokenizer, max_length: int):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n    \n    def __len__(self):\n        return len(self.texts)\n    \n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        label = self.labels[idx]\n        \n        encoding = self.tokenizer.encode_plus(\n            text, \n            add_special_tokens=True, \n            max_length=self.max_length, \n            return_token_type_ids=False, \n            padding=\"max_length\",\n            truncation=True, \n            return_attention_mask=True, \n            return_tensors=\"pt\"\n        )\n        \n        return {\n            \"input_ids\": encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'label': torch.tensor(label, dtype=torch.long)\n        }","metadata":{"execution":{"iopub.status.busy":"2024-11-06T12:31:26.072370Z","iopub.execute_input":"2024-11-06T12:31:26.072733Z","iopub.status.idle":"2024-11-06T12:31:29.268890Z","shell.execute_reply.started":"2024-11-06T12:31:26.072697Z","shell.execute_reply":"2024-11-06T12:31:29.267807Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from transformers import BartTokenizer, BartModel, AdamW\n\nmax_length = 128\n\ntokenizer = BartTokenizer.from_pretrained('facebook/bart-base')\ntrain_dataset = ClassificationDataset(train_data, train_label, tokenizer, max_length)\ndev_dataset = ClassificationDataset(dev_data, dev_label, tokenizer, max_length)","metadata":{"execution":{"iopub.status.busy":"2024-11-06T12:31:29.270953Z","iopub.execute_input":"2024-11-06T12:31:29.271843Z","iopub.status.idle":"2024-11-06T12:31:32.961447Z","shell.execute_reply.started":"2024-11-06T12:31:29.271794Z","shell.execute_reply":"2024-11-06T12:31:32.960346Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce7c2bb889d244edb0aafc1522982557"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d6313dc7e4040ac88ef26bf81d72f16"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13ac0308274f43c5a18d2069cfb26911"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.72k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b01067fb85b34f15bdb34fc945536f87"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"batch_size = 32\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ndev_loader = DataLoader(dev_dataset, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-11-06T12:31:32.962739Z","iopub.execute_input":"2024-11-06T12:31:32.963186Z","iopub.status.idle":"2024-11-06T12:31:32.968757Z","shell.execute_reply.started":"2024-11-06T12:31:32.963152Z","shell.execute_reply":"2024-11-06T12:31:32.967630Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"test_dataset = ClassificationDataset(test_data, test_label, tokenizer, max_length)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-11-06T12:31:32.971099Z","iopub.execute_input":"2024-11-06T12:31:32.971449Z","iopub.status.idle":"2024-11-06T12:31:32.980658Z","shell.execute_reply.started":"2024-11-06T12:31:32.971413Z","shell.execute_reply":"2024-11-06T12:31:32.979744Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Model Preparation","metadata":{}},{"cell_type":"code","source":"num_classes = 4","metadata":{"execution":{"iopub.status.busy":"2024-11-06T12:31:32.981836Z","iopub.execute_input":"2024-11-06T12:31:32.982138Z","iopub.status.idle":"2024-11-06T12:31:32.992913Z","shell.execute_reply.started":"2024-11-06T12:31:32.982106Z","shell.execute_reply":"2024-11-06T12:31:32.992112Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"class BARTClassifier(nn.Module):\n    def __init__(self, bart_model, num_classes, dropout=0.1):\n        super(BARTClassifier, self).__init__()\n        self.bart = bart_model\n        self.dropout = nn.Dropout(dropout)\n        self.ffn = nn.Sequential(\n            nn.Linear(768, 256),\n            nn.ReLU(),\n            nn.Linear(256, num_classes)\n        )\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.bart(input_ids=input_ids, attention_mask=attention_mask)\n        \n        last_hidden_state = outputs.last_hidden_state  \n        \n        attention_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n        sum_hidden_states = torch.sum(last_hidden_state * attention_mask_expanded, 1)\n        sum_attention_mask = torch.clamp(attention_mask_expanded.sum(1), min=1e-9)\n        pooled_output = sum_hidden_states / sum_attention_mask\n        \n        x = self.dropout(pooled_output)\n        logits = self.ffn(x)\n        return logits","metadata":{"execution":{"iopub.status.busy":"2024-11-06T12:31:32.994187Z","iopub.execute_input":"2024-11-06T12:31:32.994798Z","iopub.status.idle":"2024-11-06T12:31:33.005469Z","shell.execute_reply.started":"2024-11-06T12:31:32.994764Z","shell.execute_reply":"2024-11-06T12:31:33.004666Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"bart_model = BartModel.from_pretrained('facebook/bart-base')","metadata":{"execution":{"iopub.status.busy":"2024-11-06T12:31:33.006494Z","iopub.execute_input":"2024-11-06T12:31:33.006773Z","iopub.status.idle":"2024-11-06T12:31:36.586094Z","shell.execute_reply.started":"2024-11-06T12:31:33.006743Z","shell.execute_reply":"2024-11-06T12:31:36.585281Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/558M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96db8394f07d4aafb8ba7eb0f73bb592"}},"metadata":{}}]},{"cell_type":"code","source":"model = BARTClassifier(bart_model, num_classes)","metadata":{"execution":{"iopub.status.busy":"2024-11-06T12:31:36.587231Z","iopub.execute_input":"2024-11-06T12:31:36.587525Z","iopub.status.idle":"2024-11-06T12:31:36.594384Z","shell.execute_reply.started":"2024-11-06T12:31:36.587495Z","shell.execute_reply":"2024-11-06T12:31:36.593345Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"learning_rate = 2e-5\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-11-06T12:31:36.596039Z","iopub.execute_input":"2024-11-06T12:31:36.596430Z","iopub.status.idle":"2024-11-06T12:31:36.972874Z","shell.execute_reply.started":"2024-11-06T12:31:36.596384Z","shell.execute_reply":"2024-11-06T12:31:36.971913Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"BARTClassifier(\n  (bart): BartModel(\n    (shared): BartScaledWordEmbedding(50265, 768, padding_idx=1)\n    (encoder): BartEncoder(\n      (embed_tokens): BartScaledWordEmbedding(50265, 768, padding_idx=1)\n      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n      (layers): ModuleList(\n        (0-5): 6 x BartEncoderLayer(\n          (self_attn): BartSdpaAttention(\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (activation_fn): GELUActivation()\n          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n    )\n    (decoder): BartDecoder(\n      (embed_tokens): BartScaledWordEmbedding(50265, 768, padding_idx=1)\n      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n      (layers): ModuleList(\n        (0-5): 6 x BartDecoderLayer(\n          (self_attn): BartSdpaAttention(\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (activation_fn): GELUActivation()\n          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (encoder_attn): BartSdpaAttention(\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (ffn): Sequential(\n    (0): Linear(in_features=768, out_features=256, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=256, out_features=4, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\nimport numpy as np\nfrom tqdm import tqdm\n\ndef calculate_metrics(y_true, y_pred, y_pred_proba, num_classes):\n    metrics = {\n        'accuracy': accuracy_score(y_true, y_pred),\n        'precision': precision_score(y_true, y_pred, average='weighted'),\n        'recall': recall_score(y_true, y_pred, average='weighted'),\n        'f1': f1_score(y_true, y_pred, average='weighted')\n    }\n    \n    # Calculate ROC-AUC score\n    if num_classes == 2:\n        metrics['roc_auc'] = roc_auc_score(y_true, y_pred_proba[:, 1])\n    else:\n        try:\n            metrics['roc_auc'] = roc_auc_score(y_true, y_pred_proba, multi_class='ovr', average='weighted')\n        except:\n            metrics['roc_auc'] = None\n            \n    return metrics","metadata":{"execution":{"iopub.status.busy":"2024-11-06T12:31:36.976006Z","iopub.execute_input":"2024-11-06T12:31:36.976315Z","iopub.status.idle":"2024-11-06T12:31:37.534221Z","shell.execute_reply.started":"2024-11-06T12:31:36.976271Z","shell.execute_reply":"2024-11-06T12:31:37.533229Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def evaluate(model, data_loader, device, num_classes):\n    model.eval()\n    all_labels = []\n    all_predictions = []\n    all_predictions_proba = []\n\n    with torch.no_grad():\n        for batch in data_loader:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['label'].to(device)\n\n            outputs = model(input_ids, attention_mask)\n            probabilities = torch.softmax(outputs, dim=1)\n            _, predicted = torch.max(outputs, 1)\n            \n            all_labels.extend(labels.cpu().numpy())\n            all_predictions.extend(predicted.cpu().numpy())\n            all_predictions_proba.extend(probabilities.cpu().numpy())\n\n    all_labels = np.array(all_labels)\n    all_predictions = np.array(all_predictions)\n    all_predictions_proba = np.array(all_predictions_proba)\n\n    return calculate_metrics(all_labels, all_predictions, all_predictions_proba, num_classes)","metadata":{"execution":{"iopub.status.busy":"2024-11-06T12:31:37.535481Z","iopub.execute_input":"2024-11-06T12:31:37.535976Z","iopub.status.idle":"2024-11-06T12:31:37.544347Z","shell.execute_reply.started":"2024-11-06T12:31:37.535941Z","shell.execute_reply":"2024-11-06T12:31:37.543442Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def train(model, train_loader, val_loader, criterion, optimizer, device, num_epochs):\n    best_val_metrics = {'f1': 0.0}\n    history = {'train': [], 'val': []}\n\n    for epoch in range(num_epochs):\n        # Training phase\n        model.train()\n        train_loss = 0.0\n        all_train_labels = []\n        all_train_predictions = []\n        all_train_predictions_proba = []\n\n        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['label'].to(device)\n\n            optimizer.zero_grad()\n            outputs = model(input_ids, attention_mask)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            train_loss += loss.item()\n            probabilities = torch.softmax(outputs, dim=1)\n            _, predicted = torch.max(outputs, 1)\n            \n            all_train_labels.extend(labels.cpu().numpy())\n            all_train_predictions.extend(predicted.cpu().numpy())\n            all_train_predictions_proba.extend(probabilities.cpu().detach().numpy())\n\n        # Calculate training metrics\n        all_train_labels = np.array(all_train_labels)\n        all_train_predictions = np.array(all_train_predictions)\n        all_train_predictions_proba = np.array(all_train_predictions_proba)\n        train_metrics = calculate_metrics(all_train_labels, all_train_predictions, \n                                       all_train_predictions_proba, num_classes)\n        \n        # Validation phase\n        val_metrics = evaluate(model, val_loader, device, num_classes)\n        \n        # Store metrics history\n        history['train'].append({\n            'loss': train_loss / len(train_loader),\n            **train_metrics\n        })\n        history['val'].append(val_metrics)\n\n        # Print epoch results\n        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n        print(\"Training Metrics:\")\n        print(f\"Loss: {train_loss/len(train_loader):.4f}\")\n        for metric, value in train_metrics.items():\n            print(f\"{metric.capitalize()}: {value:.4f}\")\n        \n        print(\"\\nValidation Metrics:\")\n        for metric, value in val_metrics.items():\n            print(f\"{metric.capitalize()}: {value:.4f}\")\n    \n    return history","metadata":{"execution":{"iopub.status.busy":"2024-11-06T12:31:37.545765Z","iopub.execute_input":"2024-11-06T12:31:37.546147Z","iopub.status.idle":"2024-11-06T12:31:37.595496Z","shell.execute_reply.started":"2024-11-06T12:31:37.546103Z","shell.execute_reply":"2024-11-06T12:31:37.594609Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"num_epochs = 5\n\noptimizer = AdamW(model.parameters(), lr=learning_rate)\ncriterion = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2024-11-06T12:31:37.596583Z","iopub.execute_input":"2024-11-06T12:31:37.596984Z","iopub.status.idle":"2024-11-06T12:31:38.225190Z","shell.execute_reply.started":"2024-11-06T12:31:37.596938Z","shell.execute_reply":"2024-11-06T12:31:38.224340Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"history = train(model, train_loader, dev_loader, criterion, optimizer, device, num_epochs)","metadata":{"execution":{"iopub.status.busy":"2024-11-06T12:31:38.226279Z","iopub.execute_input":"2024-11-06T12:31:38.226728Z","iopub.status.idle":"2024-11-06T12:33:39.930184Z","shell.execute_reply.started":"2024-11-06T12:31:38.226695Z","shell.execute_reply":"2024-11-06T12:33:39.929274Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"Epoch 1/5: 100%|██████████| 49/49 [00:22<00:00,  2.14it/s]\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1/5\nTraining Metrics:\nLoss: 1.3987\nAccuracy: 0.2749\nPrecision: 0.2759\nRecall: 0.2749\nF1: 0.2751\nRoc_auc: 0.5181\n\nValidation Metrics:\nAccuracy: 0.2969\nPrecision: 0.3768\nRecall: 0.2969\nF1: 0.1968\nRoc_auc: 0.5521\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/5: 100%|██████████| 49/49 [00:21<00:00,  2.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 2/5\nTraining Metrics:\nLoss: 1.3728\nAccuracy: 0.2942\nPrecision: 0.2981\nRecall: 0.2942\nF1: 0.2920\nRoc_auc: 0.5599\n\nValidation Metrics:\nAccuracy: 0.3052\nPrecision: 0.3309\nRecall: 0.3052\nF1: 0.3007\nRoc_auc: 0.6071\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/5: 100%|██████████| 49/49 [00:21<00:00,  2.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 3/5\nTraining Metrics:\nLoss: 1.2955\nAccuracy: 0.3738\nPrecision: 0.3748\nRecall: 0.3738\nF1: 0.3686\nRoc_auc: 0.6509\n\nValidation Metrics:\nAccuracy: 0.3588\nPrecision: 0.5245\nRecall: 0.3588\nF1: 0.3018\nRoc_auc: 0.6758\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/5: 100%|██████████| 49/49 [00:21<00:00,  2.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 4/5\nTraining Metrics:\nLoss: 1.1699\nAccuracy: 0.4631\nPrecision: 0.4786\nRecall: 0.4631\nF1: 0.4634\nRoc_auc: 0.7314\n\nValidation Metrics:\nAccuracy: 0.4165\nPrecision: 0.5230\nRecall: 0.4165\nF1: 0.3875\nRoc_auc: 0.6956\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/5: 100%|██████████| 49/49 [00:21<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 5/5\nTraining Metrics:\nLoss: 1.0138\nAccuracy: 0.5478\nPrecision: 0.5499\nRecall: 0.5478\nF1: 0.5479\nRoc_auc: 0.8101\n\nValidation Metrics:\nAccuracy: 0.4680\nPrecision: 0.5381\nRecall: 0.4680\nF1: 0.4500\nRoc_auc: 0.7600\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\n\npd.DataFrame(history['train'])","metadata":{"execution":{"iopub.status.busy":"2024-11-06T12:33:39.931504Z","iopub.execute_input":"2024-11-06T12:33:39.931813Z","iopub.status.idle":"2024-11-06T12:33:39.949572Z","shell.execute_reply.started":"2024-11-06T12:33:39.931780Z","shell.execute_reply":"2024-11-06T12:33:39.948685Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"       loss  accuracy  precision    recall        f1   roc_auc\n0  1.398662  0.274888   0.275871  0.274888  0.275122  0.518078\n1  1.372799  0.294155   0.298124  0.294155  0.292012  0.559872\n2  1.295494  0.373796   0.374798  0.373796  0.368625  0.650887\n3  1.169875  0.463070   0.478559  0.463070  0.463365  0.731411\n4  1.013805  0.547848   0.549853  0.547848  0.547880  0.810071","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>loss</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n      <th>roc_auc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.398662</td>\n      <td>0.274888</td>\n      <td>0.275871</td>\n      <td>0.274888</td>\n      <td>0.275122</td>\n      <td>0.518078</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.372799</td>\n      <td>0.294155</td>\n      <td>0.298124</td>\n      <td>0.294155</td>\n      <td>0.292012</td>\n      <td>0.559872</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.295494</td>\n      <td>0.373796</td>\n      <td>0.374798</td>\n      <td>0.373796</td>\n      <td>0.368625</td>\n      <td>0.650887</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.169875</td>\n      <td>0.463070</td>\n      <td>0.478559</td>\n      <td>0.463070</td>\n      <td>0.463365</td>\n      <td>0.731411</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.013805</td>\n      <td>0.547848</td>\n      <td>0.549853</td>\n      <td>0.547848</td>\n      <td>0.547880</td>\n      <td>0.810071</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"pd.DataFrame(history['val'])","metadata":{"execution":{"iopub.status.busy":"2024-11-06T12:33:39.950734Z","iopub.execute_input":"2024-11-06T12:33:39.951541Z","iopub.status.idle":"2024-11-06T12:33:39.963064Z","shell.execute_reply.started":"2024-11-06T12:33:39.951506Z","shell.execute_reply":"2024-11-06T12:33:39.962166Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"   accuracy  precision    recall        f1   roc_auc\n0  0.296907   0.376760  0.296907  0.196826  0.552061\n1  0.305155   0.330851  0.305155  0.300745  0.607122\n2  0.358763   0.524548  0.358763  0.301805  0.675825\n3  0.416495   0.522953  0.416495  0.387463  0.695595\n4  0.468041   0.538070  0.468041  0.450003  0.759994","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n      <th>roc_auc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.296907</td>\n      <td>0.376760</td>\n      <td>0.296907</td>\n      <td>0.196826</td>\n      <td>0.552061</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.305155</td>\n      <td>0.330851</td>\n      <td>0.305155</td>\n      <td>0.300745</td>\n      <td>0.607122</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.358763</td>\n      <td>0.524548</td>\n      <td>0.358763</td>\n      <td>0.301805</td>\n      <td>0.675825</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.416495</td>\n      <td>0.522953</td>\n      <td>0.416495</td>\n      <td>0.387463</td>\n      <td>0.695595</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.468041</td>\n      <td>0.538070</td>\n      <td>0.468041</td>\n      <td>0.450003</td>\n      <td>0.759994</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"evaluate(model, test_loader, device, num_classes)","metadata":{"execution":{"iopub.status.busy":"2024-11-06T12:33:39.964264Z","iopub.execute_input":"2024-11-06T12:33:39.964583Z","iopub.status.idle":"2024-11-06T12:33:42.414400Z","shell.execute_reply.started":"2024-11-06T12:33:39.964550Z","shell.execute_reply":"2024-11-06T12:33:42.413465Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"{'accuracy': 0.4480769230769231,\n 'precision': 0.488505638139971,\n 'recall': 0.4480769230769231,\n 'f1': 0.43469232877811625,\n 'roc_auc': 0.7397927481391136}"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}