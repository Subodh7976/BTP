{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9364160,"sourceType":"datasetVersion","datasetId":5678141}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Data Ingestion","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\ncolumn_names = ['id', 'text', 'label']\ntwitter_15_train = pd.read_csv(\"/kaggle/input/twitter15-16/twitter15.train\", sep=\"\\t\", \n                               header=None, names=column_names)\ntwitter_15_test = pd.read_csv(\"/kaggle/input/twitter15-16/twitter15.test\", sep=\"\\t\", \n                              header=None, names=column_names)\ntwitter_15_dev = pd.read_csv(\"/kaggle/input/twitter15-16/twitter15.dev\", sep=\"\\t\", \n                             header=None, names=column_names)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-27T15:07:41.142472Z","iopub.execute_input":"2024-10-27T15:07:41.142857Z","iopub.status.idle":"2024-10-27T15:07:41.592358Z","shell.execute_reply.started":"2024-10-27T15:07:41.142819Z","shell.execute_reply":"2024-10-27T15:07:41.591311Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"twitter_15_train.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-27T15:07:42.728648Z","iopub.execute_input":"2024-10-27T15:07:42.729022Z","iopub.status.idle":"2024-10-27T15:07:42.747587Z","shell.execute_reply.started":"2024-10-27T15:07:42.728987Z","shell.execute_reply":"2024-10-27T15:07:42.746723Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"                   id                                               text  \\\n0  724703995147751424  american family association gets 500,000 to si...   \n1  358591089462099968  this week's top story: george zimmerman wins f...   \n2  775672628493357057  clinton hides failing health? full disclosure ...   \n3  364589696573124609  fukushima: highly radioactive water seeping in...   \n4  549927969032916993  a transgender 17-year old left a suicide note ...   \n\n        label  \n0  unverified  \n1       false  \n2  unverified  \n3       false  \n4  unverified  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>724703995147751424</td>\n      <td>american family association gets 500,000 to si...</td>\n      <td>unverified</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>358591089462099968</td>\n      <td>this week's top story: george zimmerman wins f...</td>\n      <td>false</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>775672628493357057</td>\n      <td>clinton hides failing health? full disclosure ...</td>\n      <td>unverified</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>364589696573124609</td>\n      <td>fukushima: highly radioactive water seeping in...</td>\n      <td>false</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>549927969032916993</td>\n      <td>a transgender 17-year old left a suicide note ...</td>\n      <td>unverified</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"twitter_15_train.shape, twitter_15_test.shape, twitter_15_dev.shape","metadata":{"execution":{"iopub.status.busy":"2024-10-27T15:07:43.807020Z","iopub.execute_input":"2024-10-27T15:07:43.807841Z","iopub.status.idle":"2024-10-27T15:07:43.814073Z","shell.execute_reply.started":"2024-10-27T15:07:43.807795Z","shell.execute_reply":"2024-10-27T15:07:43.813161Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"((1005, 3), (336, 3), (149, 3))"},"metadata":{}}]},{"cell_type":"code","source":"twitter_16_train = pd.read_csv(\"/kaggle/input/twitter15-16/twitter16.train\", sep=\"\\t\", \n                               header=None, names=column_names)\ntwitter_16_test = pd.read_csv(\"/kaggle/input/twitter15-16/twitter16.test\", sep=\"\\t\", \n                              header=None, names=column_names)\ntwitter_16_dev = pd.read_csv(\"/kaggle/input/twitter15-16/twitter16.dev\", sep=\"\\t\", \n                             header=None, names=column_names)","metadata":{"execution":{"iopub.status.busy":"2024-10-27T15:07:44.636502Z","iopub.execute_input":"2024-10-27T15:07:44.636849Z","iopub.status.idle":"2024-10-27T15:07:44.659057Z","shell.execute_reply.started":"2024-10-27T15:07:44.636816Z","shell.execute_reply":"2024-10-27T15:07:44.658191Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"twitter_16_train.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-27T15:07:45.491611Z","iopub.execute_input":"2024-10-27T15:07:45.492472Z","iopub.status.idle":"2024-10-27T15:07:45.502101Z","shell.execute_reply.started":"2024-10-27T15:07:45.492430Z","shell.execute_reply":"2024-10-27T15:07:45.501210Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                   id                                               text  \\\n0  692929779696275456  ohio lawmakers want to know why state’s epa di...   \n1  693858804279201794  poor women in india are fighting for the right...   \n2  693648684857323521  spoiler alert: leo and kate were ridiculously ...   \n3  620367840902782976           translucent butterfly - beautiful! ' URL   \n4  693939356390653952  michael oher got a text from cam newton during...   \n\n       label  \n0  non-rumor  \n1  non-rumor  \n2  non-rumor  \n3      false  \n4  non-rumor  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>692929779696275456</td>\n      <td>ohio lawmakers want to know why state’s epa di...</td>\n      <td>non-rumor</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>693858804279201794</td>\n      <td>poor women in india are fighting for the right...</td>\n      <td>non-rumor</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>693648684857323521</td>\n      <td>spoiler alert: leo and kate were ridiculously ...</td>\n      <td>non-rumor</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>620367840902782976</td>\n      <td>translucent butterfly - beautiful! ' URL</td>\n      <td>false</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>693939356390653952</td>\n      <td>michael oher got a text from cam newton during...</td>\n      <td>non-rumor</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"twitter_16_train.shape, twitter_16_test.shape, twitter_16_dev.shape","metadata":{"execution":{"iopub.status.busy":"2024-10-27T15:07:46.355618Z","iopub.execute_input":"2024-10-27T15:07:46.356410Z","iopub.status.idle":"2024-10-27T15:07:46.362493Z","shell.execute_reply.started":"2024-10-27T15:07:46.356368Z","shell.execute_reply":"2024-10-27T15:07:46.361554Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"((552, 3), (184, 3), (82, 3))"},"metadata":{}}]},{"cell_type":"code","source":"twitter_train = pd.concat([twitter_15_train, twitter_16_train], ignore_index=True, axis=0)\ntwitter_test = pd.concat([twitter_15_test, twitter_16_test], ignore_index=True, axis=0)\ntwitter_dev = pd.concat([twitter_15_dev, twitter_15_test], ignore_index=True, axis=0)","metadata":{"execution":{"iopub.status.busy":"2024-10-27T15:07:47.382748Z","iopub.execute_input":"2024-10-27T15:07:47.383377Z","iopub.status.idle":"2024-10-27T15:07:47.391272Z","shell.execute_reply.started":"2024-10-27T15:07:47.383337Z","shell.execute_reply":"2024-10-27T15:07:47.389847Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"twitter_train.shape, twitter_test.shape, twitter_dev.shape","metadata":{"execution":{"iopub.status.busy":"2024-10-27T15:07:48.225048Z","iopub.execute_input":"2024-10-27T15:07:48.225453Z","iopub.status.idle":"2024-10-27T15:07:48.234254Z","shell.execute_reply.started":"2024-10-27T15:07:48.225413Z","shell.execute_reply":"2024-10-27T15:07:48.233177Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"((1557, 3), (520, 3), (485, 3))"},"metadata":{}}]},{"cell_type":"markdown","source":"## Data Preparation","metadata":{}},{"cell_type":"code","source":"LABELS = twitter_train['label'].unique().tolist()\ntrain_label = twitter_train['label'].replace(LABELS, [0, 1, 2, 3]).tolist()","metadata":{"execution":{"iopub.status.busy":"2024-10-27T15:07:49.810078Z","iopub.execute_input":"2024-10-27T15:07:49.810959Z","iopub.status.idle":"2024-10-27T15:07:49.821748Z","shell.execute_reply.started":"2024-10-27T15:07:49.810919Z","shell.execute_reply":"2024-10-27T15:07:49.820855Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/3616623573.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  train_label = twitter_train['label'].replace(LABELS, [0, 1, 2, 3]).tolist()\n","output_type":"stream"}]},{"cell_type":"code","source":"train_data = twitter_train['text'].tolist()","metadata":{"execution":{"iopub.status.busy":"2024-10-27T15:07:53.425173Z","iopub.execute_input":"2024-10-27T15:07:53.425854Z","iopub.status.idle":"2024-10-27T15:07:53.430201Z","shell.execute_reply.started":"2024-10-27T15:07:53.425816Z","shell.execute_reply":"2024-10-27T15:07:53.429203Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"dev_data = twitter_dev['text'].tolist()\ndev_label = twitter_dev['label'].replace(LABELS, [0, 1, 2, 3]).tolist()","metadata":{"execution":{"iopub.status.busy":"2024-10-27T15:08:01.057309Z","iopub.execute_input":"2024-10-27T15:08:01.057685Z","iopub.status.idle":"2024-10-27T15:08:01.064578Z","shell.execute_reply.started":"2024-10-27T15:08:01.057651Z","shell.execute_reply":"2024-10-27T15:08:01.063606Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/3987848631.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  dev_label = twitter_dev['label'].replace(LABELS, [0, 1, 2, 3]).tolist()\n","output_type":"stream"}]},{"cell_type":"code","source":"test_data = twitter_test['text'].tolist()\ntest_label = twitter_test['label'].replace(LABELS, [0, 1, 2, 3]).tolist()","metadata":{"execution":{"iopub.status.busy":"2024-10-27T15:08:03.401726Z","iopub.execute_input":"2024-10-27T15:08:03.402905Z","iopub.status.idle":"2024-10-27T15:08:03.410294Z","shell.execute_reply.started":"2024-10-27T15:08:03.402852Z","shell.execute_reply":"2024-10-27T15:08:03.409357Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/2548705681.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  test_label = twitter_test['label'].replace(LABELS, [0, 1, 2, 3]).tolist()\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\n\nclass ClassificationDataset(Dataset):\n    def __init__(self, texts: list[str], labels: list[int], tokenizer, max_length: int):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n    \n    def __len__(self):\n        return len(self.texts)\n    \n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        label = self.labels[idx]\n        \n        encoding = self.tokenizer.encode_plus(\n            text, \n            add_special_tokens=True, \n            max_length=self.max_length, \n            return_token_type_ids=False, \n            padding=\"max_length\",\n            truncation=True, \n            return_attention_mask=True, \n            return_tensors=\"pt\"\n        )\n        \n        return {\n            \"input_ids\": encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'label': torch.tensor(label, dtype=torch.long)\n        }","metadata":{"execution":{"iopub.status.busy":"2024-10-27T15:08:04.451241Z","iopub.execute_input":"2024-10-27T15:08:04.451602Z","iopub.status.idle":"2024-10-27T15:08:07.795545Z","shell.execute_reply.started":"2024-10-27T15:08:04.451569Z","shell.execute_reply":"2024-10-27T15:08:07.794669Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from transformers import RobertaTokenizer, RobertaModel, AdamW\n\nmax_length = 128\n\ntokenizer = RobertaTokenizer.from_pretrained('roberta-base')\ntrain_dataset = ClassificationDataset(train_data, train_label, tokenizer, max_length)\ndev_dataset = ClassificationDataset(dev_data, dev_label, tokenizer, max_length)","metadata":{"execution":{"iopub.status.busy":"2024-10-27T15:08:07.797259Z","iopub.execute_input":"2024-10-27T15:08:07.797869Z","iopub.status.idle":"2024-10-27T15:08:11.424001Z","shell.execute_reply.started":"2024-10-27T15:08:07.797823Z","shell.execute_reply":"2024-10-27T15:08:11.423027Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72e383335c3340af80c75d3d66bb0342"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dcaab7dc78aa46769e178864f8b9efd6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dfa2161329f94e87b50b45e10aae12a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cefbef79f6e54983a500f94e5d74ed73"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3575c8ed180f4c9bb7435998af474ecd"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"batch_size = 32\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ndev_loader = DataLoader(dev_dataset, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-10-27T15:08:14.150105Z","iopub.execute_input":"2024-10-27T15:08:14.151134Z","iopub.status.idle":"2024-10-27T15:08:14.155894Z","shell.execute_reply.started":"2024-10-27T15:08:14.151091Z","shell.execute_reply":"2024-10-27T15:08:14.154850Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"test_dataset = ClassificationDataset(test_data, test_label, tokenizer, max_length)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-10-27T15:08:16.903003Z","iopub.execute_input":"2024-10-27T15:08:16.903990Z","iopub.status.idle":"2024-10-27T15:08:16.908699Z","shell.execute_reply.started":"2024-10-27T15:08:16.903937Z","shell.execute_reply":"2024-10-27T15:08:16.907804Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"## Model Preparation","metadata":{}},{"cell_type":"code","source":"num_classes = 4","metadata":{"execution":{"iopub.status.busy":"2024-10-27T15:08:20.477165Z","iopub.execute_input":"2024-10-27T15:08:20.478070Z","iopub.status.idle":"2024-10-27T15:08:20.482044Z","shell.execute_reply.started":"2024-10-27T15:08:20.478029Z","shell.execute_reply":"2024-10-27T15:08:20.481103Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"class RobertaClassifier(nn.Module):\n    def __init__(self, roberta_model, num_classes, dropout=0.1):\n        super(RobertaClassifier, self).__init__()\n        self.roberta = roberta_model\n        self.dropout = nn.Dropout(dropout)\n        self.ffn = nn.Sequential(\n            nn.Linear(768, 256),\n            nn.ReLU(),\n            nn.Linear(256, num_classes)\n        )\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n        pooled_output = outputs.pooler_output\n        x = self.dropout(pooled_output)\n        logits = self.ffn(x)\n        return logits","metadata":{"execution":{"iopub.status.busy":"2024-10-27T15:20:21.955643Z","iopub.execute_input":"2024-10-27T15:20:21.956044Z","iopub.status.idle":"2024-10-27T15:20:21.963173Z","shell.execute_reply.started":"2024-10-27T15:20:21.956009Z","shell.execute_reply":"2024-10-27T15:20:21.962197Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"roberta_model = RobertaModel.from_pretrained('roberta-base')","metadata":{"execution":{"iopub.status.busy":"2024-10-27T15:21:19.089639Z","iopub.execute_input":"2024-10-27T15:21:19.090052Z","iopub.status.idle":"2024-10-27T15:21:19.434323Z","shell.execute_reply.started":"2024-10-27T15:21:19.090015Z","shell.execute_reply":"2024-10-27T15:21:19.433385Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"model = RobertaClassifier(roberta_model, num_classes)","metadata":{"execution":{"iopub.status.busy":"2024-10-27T15:21:19.436162Z","iopub.execute_input":"2024-10-27T15:21:19.436566Z","iopub.status.idle":"2024-10-27T15:21:19.442361Z","shell.execute_reply.started":"2024-10-27T15:21:19.436521Z","shell.execute_reply":"2024-10-27T15:21:19.441523Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"learning_rate = 2e-5\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-10-27T15:21:19.505791Z","iopub.execute_input":"2024-10-27T15:21:19.506088Z","iopub.status.idle":"2024-10-27T15:21:19.671579Z","shell.execute_reply.started":"2024-10-27T15:21:19.506056Z","shell.execute_reply":"2024-10-27T15:21:19.670693Z"},"trusted":true},"execution_count":58,"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"RobertaClassifier(\n  (roberta): RobertaModel(\n    (embeddings): RobertaEmbeddings(\n      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n      (position_embeddings): Embedding(514, 768, padding_idx=1)\n      (token_type_embeddings): Embedding(1, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): RobertaEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): RobertaPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (ffn): Sequential(\n    (0): Linear(in_features=768, out_features=256, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=256, out_features=4, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\nimport numpy as np\n\ndef calculate_metrics(y_true, y_pred, y_pred_proba, num_classes):\n    metrics = {\n        'accuracy': accuracy_score(y_true, y_pred),\n        'precision': precision_score(y_true, y_pred, average='weighted'),\n        'recall': recall_score(y_true, y_pred, average='weighted'),\n        'f1': f1_score(y_true, y_pred, average='weighted')\n    }\n    \n    # Calculate ROC-AUC score\n    if num_classes == 2:\n        metrics['roc_auc'] = roc_auc_score(y_true, y_pred_proba[:, 1])\n    else:\n        try:\n            metrics['roc_auc'] = roc_auc_score(y_true, y_pred_proba, multi_class='ovr', average='weighted')\n        except:\n            metrics['roc_auc'] = None\n            \n    return metrics","metadata":{"execution":{"iopub.status.busy":"2024-10-27T15:21:19.906699Z","iopub.execute_input":"2024-10-27T15:21:19.907031Z","iopub.status.idle":"2024-10-27T15:21:19.914288Z","shell.execute_reply.started":"2024-10-27T15:21:19.906998Z","shell.execute_reply":"2024-10-27T15:21:19.913272Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"def evaluate(model, data_loader, device, num_classes):\n    model.eval()\n    all_labels = []\n    all_predictions = []\n    all_predictions_proba = []\n\n    with torch.no_grad():\n        for batch in data_loader:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['label'].to(device)\n\n            outputs = model(input_ids, attention_mask)\n            probabilities = torch.softmax(outputs, dim=1)\n            _, predicted = torch.max(outputs, 1)\n            \n            all_labels.extend(labels.cpu().numpy())\n            all_predictions.extend(predicted.cpu().numpy())\n            all_predictions_proba.extend(probabilities.cpu().numpy())\n\n    all_labels = np.array(all_labels)\n    all_predictions = np.array(all_predictions)\n    all_predictions_proba = np.array(all_predictions_proba)\n\n    return calculate_metrics(all_labels, all_predictions, all_predictions_proba, num_classes)","metadata":{"execution":{"iopub.status.busy":"2024-10-27T15:21:20.088510Z","iopub.execute_input":"2024-10-27T15:21:20.089357Z","iopub.status.idle":"2024-10-27T15:21:20.097303Z","shell.execute_reply.started":"2024-10-27T15:21:20.089316Z","shell.execute_reply":"2024-10-27T15:21:20.096205Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"def train(model, train_loader, val_loader, criterion, optimizer, device, num_epochs):\n    best_val_metrics = {'f1': 0.0}\n    history = {'train': [], 'val': []}\n\n    for epoch in range(num_epochs):\n        # Training phase\n        model.train()\n        train_loss = 0.0\n        all_train_labels = []\n        all_train_predictions = []\n        all_train_predictions_proba = []\n\n        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['label'].to(device)\n\n            optimizer.zero_grad()\n            outputs = model(input_ids, attention_mask)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            train_loss += loss.item()\n            probabilities = torch.softmax(outputs, dim=1)\n            _, predicted = torch.max(outputs, 1)\n            \n            all_train_labels.extend(labels.cpu().numpy())\n            all_train_predictions.extend(predicted.cpu().numpy())\n            all_train_predictions_proba.extend(probabilities.cpu().detach().numpy())\n\n        # Calculate training metrics\n        all_train_labels = np.array(all_train_labels)\n        all_train_predictions = np.array(all_train_predictions)\n        all_train_predictions_proba = np.array(all_train_predictions_proba)\n        train_metrics = calculate_metrics(all_train_labels, all_train_predictions, \n                                       all_train_predictions_proba, num_classes)\n        \n        # Validation phase\n        val_metrics = evaluate(model, val_loader, device, num_classes)\n        \n        # Store metrics history\n        history['train'].append({\n            'loss': train_loss / len(train_loader),\n            **train_metrics\n        })\n        history['val'].append(val_metrics)\n\n        # Print epoch results\n        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n        print(\"Training Metrics:\")\n        print(f\"Loss: {train_loss/len(train_loader):.4f}\")\n        for metric, value in train_metrics.items():\n            print(f\"{metric.capitalize()}: {value:.4f}\")\n        \n        print(\"\\nValidation Metrics:\")\n        for metric, value in val_metrics.items():\n            print(f\"{metric.capitalize()}: {value:.4f}\")\n\n        # Save best model based on validation F1 score\n        if val_metrics['f1'] > best_val_metrics['f1']:\n            best_val_metrics = val_metrics\n            torch.save({\n                'epoch': epoch,\n                'model_state_dict': model.state_dict(),\n                'optimizer_state_dict': optimizer.state_dict(),\n                'metrics': val_metrics,\n            }, 'best_model.pth')\n\n    print(\"\\nBest Validation Metrics:\")\n    for metric, value in best_val_metrics.items():\n        print(f\"{metric.capitalize()}: {value:.4f}\")\n    \n    return history","metadata":{"execution":{"iopub.status.busy":"2024-10-27T15:21:20.590540Z","iopub.execute_input":"2024-10-27T15:21:20.591317Z","iopub.status.idle":"2024-10-27T15:21:20.605675Z","shell.execute_reply.started":"2024-10-27T15:21:20.591280Z","shell.execute_reply":"2024-10-27T15:21:20.604625Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"num_epochs = 5\n\noptimizer = AdamW(model.parameters(), lr=learning_rate)\ncriterion = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2024-10-27T15:21:21.039363Z","iopub.execute_input":"2024-10-27T15:21:21.039739Z","iopub.status.idle":"2024-10-27T15:21:21.048064Z","shell.execute_reply.started":"2024-10-27T15:21:21.039703Z","shell.execute_reply":"2024-10-27T15:21:21.047110Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"history = train(model, train_loader, dev_loader, criterion, optimizer, device, num_epochs)","metadata":{"execution":{"iopub.status.busy":"2024-10-27T15:21:21.536721Z","iopub.execute_input":"2024-10-27T15:21:21.537072Z","iopub.status.idle":"2024-10-27T15:23:13.165900Z","shell.execute_reply.started":"2024-10-27T15:21:21.537037Z","shell.execute_reply":"2024-10-27T15:23:13.164907Z"},"trusted":true},"execution_count":63,"outputs":[{"name":"stderr","text":"Epoch 1/5: 100%|██████████| 49/49 [00:18<00:00,  2.71it/s]\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1/5\nTraining Metrics:\nLoss: 1.3867\nAccuracy: 0.2511\nPrecision: 0.2470\nRecall: 0.2511\nF1: 0.2240\nRoc_auc: 0.5087\n\nValidation Metrics:\nAccuracy: 0.3320\nPrecision: 0.2468\nRecall: 0.3320\nF1: 0.2414\nRoc_auc: 0.6852\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/5: 100%|██████████| 49/49 [00:18<00:00,  2.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 2/5\nTraining Metrics:\nLoss: 1.2193\nAccuracy: 0.4868\nPrecision: 0.4890\nRecall: 0.4868\nF1: 0.4760\nRoc_auc: 0.7243\n\nValidation Metrics:\nAccuracy: 0.5629\nPrecision: 0.5588\nRecall: 0.5629\nF1: 0.5449\nRoc_auc: 0.8184\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/5: 100%|██████████| 49/49 [00:18<00:00,  2.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 3/5\nTraining Metrics:\nLoss: 0.8319\nAccuracy: 0.7065\nPrecision: 0.7050\nRecall: 0.7065\nF1: 0.7054\nRoc_auc: 0.8896\n\nValidation Metrics:\nAccuracy: 0.7505\nPrecision: 0.7581\nRecall: 0.7505\nF1: 0.7508\nRoc_auc: 0.9117\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/5: 100%|██████████| 49/49 [00:18<00:00,  2.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 4/5\nTraining Metrics:\nLoss: 0.4943\nAccuracy: 0.8504\nPrecision: 0.8512\nRecall: 0.8504\nF1: 0.8504\nRoc_auc: 0.9590\n\nValidation Metrics:\nAccuracy: 0.8082\nPrecision: 0.8126\nRecall: 0.8082\nF1: 0.8067\nRoc_auc: 0.9365\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/5: 100%|██████████| 49/49 [00:18<00:00,  2.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 5/5\nTraining Metrics:\nLoss: 0.2782\nAccuracy: 0.9242\nPrecision: 0.9248\nRecall: 0.9242\nF1: 0.9241\nRoc_auc: 0.9861\n\nValidation Metrics:\nAccuracy: 0.8000\nPrecision: 0.8128\nRecall: 0.8000\nF1: 0.8021\nRoc_auc: 0.9347\n\nBest Validation Metrics:\nAccuracy: 0.8082\nPrecision: 0.8126\nRecall: 0.8082\nF1: 0.8067\nRoc_auc: 0.9365\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\n\npd.DataFrame(history['train'])","metadata":{"execution":{"iopub.status.busy":"2024-10-27T15:24:37.863011Z","iopub.execute_input":"2024-10-27T15:24:37.863893Z","iopub.status.idle":"2024-10-27T15:24:37.877498Z","shell.execute_reply.started":"2024-10-27T15:24:37.863854Z","shell.execute_reply":"2024-10-27T15:24:37.876555Z"},"trusted":true},"execution_count":67,"outputs":[{"execution_count":67,"output_type":"execute_result","data":{"text/plain":"       loss  accuracy  precision    recall        f1   roc_auc\n0  1.386712  0.251124   0.247015  0.251124  0.224048  0.508703\n1  1.219316  0.486834   0.488960  0.486834  0.476036  0.724349\n2  0.831911  0.706487   0.704976  0.706487  0.705443  0.889604\n3  0.494267  0.850353   0.851232  0.850353  0.850406  0.959001\n4  0.278219  0.924213   0.924760  0.924213  0.924050  0.986081","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>loss</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n      <th>roc_auc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.386712</td>\n      <td>0.251124</td>\n      <td>0.247015</td>\n      <td>0.251124</td>\n      <td>0.224048</td>\n      <td>0.508703</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.219316</td>\n      <td>0.486834</td>\n      <td>0.488960</td>\n      <td>0.486834</td>\n      <td>0.476036</td>\n      <td>0.724349</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.831911</td>\n      <td>0.706487</td>\n      <td>0.704976</td>\n      <td>0.706487</td>\n      <td>0.705443</td>\n      <td>0.889604</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.494267</td>\n      <td>0.850353</td>\n      <td>0.851232</td>\n      <td>0.850353</td>\n      <td>0.850406</td>\n      <td>0.959001</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.278219</td>\n      <td>0.924213</td>\n      <td>0.924760</td>\n      <td>0.924213</td>\n      <td>0.924050</td>\n      <td>0.986081</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"pd.DataFrame(history['val'])","metadata":{"execution":{"iopub.status.busy":"2024-10-27T15:25:02.631813Z","iopub.execute_input":"2024-10-27T15:25:02.632553Z","iopub.status.idle":"2024-10-27T15:25:02.644285Z","shell.execute_reply.started":"2024-10-27T15:25:02.632509Z","shell.execute_reply":"2024-10-27T15:25:02.643439Z"},"trusted":true},"execution_count":68,"outputs":[{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"   accuracy  precision    recall        f1   roc_auc\n0  0.331959   0.246793  0.331959  0.241392  0.685222\n1  0.562887   0.558839  0.562887  0.544853  0.818406\n2  0.750515   0.758122  0.750515  0.750767  0.911731\n3  0.808247   0.812628  0.808247  0.806735  0.936492\n4  0.800000   0.812793  0.800000  0.802088  0.934678","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n      <th>roc_auc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.331959</td>\n      <td>0.246793</td>\n      <td>0.331959</td>\n      <td>0.241392</td>\n      <td>0.685222</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.562887</td>\n      <td>0.558839</td>\n      <td>0.562887</td>\n      <td>0.544853</td>\n      <td>0.818406</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.750515</td>\n      <td>0.758122</td>\n      <td>0.750515</td>\n      <td>0.750767</td>\n      <td>0.911731</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.808247</td>\n      <td>0.812628</td>\n      <td>0.808247</td>\n      <td>0.806735</td>\n      <td>0.936492</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.800000</td>\n      <td>0.812793</td>\n      <td>0.800000</td>\n      <td>0.802088</td>\n      <td>0.934678</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"evaluate(model, test_loader, device, num_classes)","metadata":{"execution":{"iopub.status.busy":"2024-10-27T15:25:36.961742Z","iopub.execute_input":"2024-10-27T15:25:36.962650Z","iopub.status.idle":"2024-10-27T15:25:39.009742Z","shell.execute_reply.started":"2024-10-27T15:25:36.962606Z","shell.execute_reply":"2024-10-27T15:25:39.008718Z"},"trusted":true},"execution_count":69,"outputs":[{"execution_count":69,"output_type":"execute_result","data":{"text/plain":"{'accuracy': 0.8057692307692308,\n 'precision': 0.8156962203710432,\n 'recall': 0.8057692307692308,\n 'f1': 0.8076031801831552,\n 'roc_auc': 0.9385079723586033}"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}