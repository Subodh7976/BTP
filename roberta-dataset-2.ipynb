{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9364544,"sourceType":"datasetVersion","datasetId":5678457}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Data Ingestion","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\ncolumn_names = ['id', 'text', 'label']\nweibo_train = pd.read_csv(\"/kaggle/input/weibo-dataset/weibo.train\", sep=\"\\t\", \n                               header=None, names=column_names)\nweibo_test = pd.read_csv(\"/kaggle/input/weibo-dataset/weibo.test\", sep=\"\\t\", \n                              header=None, names=column_names)\nweibo_dev = pd.read_csv(\"/kaggle/input/weibo-dataset/weibo.dev\", sep=\"\\t\", \n                             header=None, names=column_names)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-06T04:55:53.988194Z","iopub.execute_input":"2024-11-06T04:55:53.988583Z","iopub.status.idle":"2024-11-06T04:55:54.467775Z","shell.execute_reply.started":"2024-11-06T04:55:53.988544Z","shell.execute_reply":"2024-11-06T04:55:54.466771Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"weibo_test.dropna(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-11-06T04:55:54.469541Z","iopub.execute_input":"2024-11-06T04:55:54.470312Z","iopub.status.idle":"2024-11-06T04:55:54.480022Z","shell.execute_reply.started":"2024-11-06T04:55:54.470278Z","shell.execute_reply":"2024-11-06T04:55:54.479132Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"weibo_train.head()","metadata":{"execution":{"iopub.status.busy":"2024-11-06T04:55:54.505408Z","iopub.execute_input":"2024-11-06T04:55:54.505720Z","iopub.status.idle":"2024-11-06T04:55:54.525069Z","shell.execute_reply.started":"2024-11-06T04:55:54.505688Z","shell.execute_reply":"2024-11-06T04:55:54.524212Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                 id                                               text  \\\n0  3910552407639880  【教育部新规拟要求高校辅导员必须是中共党员】教育部日前在官网公布了《普通高等学校辅导员队伍建...   \n1  3536960792696376  【民生】特大好消息：继北京出台95岁老人看病不要钱后，山东泰安宣布100岁可免费登泰山，初步...   \n2  3921542276460163  【被疯传的投影舞 看哭了[泪]】这段不足4分钟的舞蹈由8位舞者共同完成，舞出一对情侣从相识到...   \n3  3922114622540868  #突发#【深圳一处工业园区被曝遭山体滑坡掩埋】据网友曝料，深圳光明新区红坳村柳溪工业园发生山...   \n4  3911293176451011  【“朝阳群众”注册人数已达13万！[赞]】他们大隐隐于市，不露声色却屡建奇功……目前登记在册...   \n\n       label  \n0  non-rumor  \n1      false  \n2  non-rumor  \n3  non-rumor  \n4  non-rumor  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3910552407639880</td>\n      <td>【教育部新规拟要求高校辅导员必须是中共党员】教育部日前在官网公布了《普通高等学校辅导员队伍建...</td>\n      <td>non-rumor</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3536960792696376</td>\n      <td>【民生】特大好消息：继北京出台95岁老人看病不要钱后，山东泰安宣布100岁可免费登泰山，初步...</td>\n      <td>false</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3921542276460163</td>\n      <td>【被疯传的投影舞 看哭了[泪]】这段不足4分钟的舞蹈由8位舞者共同完成，舞出一对情侣从相识到...</td>\n      <td>non-rumor</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3922114622540868</td>\n      <td>#突发#【深圳一处工业园区被曝遭山体滑坡掩埋】据网友曝料，深圳光明新区红坳村柳溪工业园发生山...</td>\n      <td>non-rumor</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3911293176451011</td>\n      <td>【“朝阳群众”注册人数已达13万！[赞]】他们大隐隐于市，不露声色却屡建奇功……目前登记在册...</td>\n      <td>non-rumor</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"weibo_train.shape, weibo_test.shape, weibo_dev.shape","metadata":{"execution":{"iopub.status.busy":"2024-11-06T04:55:54.802281Z","iopub.execute_input":"2024-11-06T04:55:54.803010Z","iopub.status.idle":"2024-11-06T04:55:54.820717Z","shell.execute_reply.started":"2024-11-06T04:55:54.802971Z","shell.execute_reply":"2024-11-06T04:55:54.819180Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"((3147, 3), (1049, 3), (467, 3))"},"metadata":{}}]},{"cell_type":"markdown","source":"## Data Preparation","metadata":{}},{"cell_type":"code","source":"LABELS = weibo_train['label'].unique().tolist()\ntrain_label = weibo_train['label'].replace(LABELS, [0, 1]).tolist()","metadata":{"execution":{"iopub.status.busy":"2024-11-06T04:55:55.465735Z","iopub.execute_input":"2024-11-06T04:55:55.466092Z","iopub.status.idle":"2024-11-06T04:55:55.478052Z","shell.execute_reply.started":"2024-11-06T04:55:55.466058Z","shell.execute_reply":"2024-11-06T04:55:55.477088Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/2429078884.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  train_label = weibo_train['label'].replace(LABELS, [0, 1]).tolist()\n","output_type":"stream"}]},{"cell_type":"code","source":"LABELS","metadata":{"execution":{"iopub.status.busy":"2024-11-06T04:55:55.809722Z","iopub.execute_input":"2024-11-06T04:55:55.810083Z","iopub.status.idle":"2024-11-06T04:55:55.816358Z","shell.execute_reply.started":"2024-11-06T04:55:55.810047Z","shell.execute_reply":"2024-11-06T04:55:55.815047Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"['non-rumor', 'false']"},"metadata":{}}]},{"cell_type":"code","source":"train_data = weibo_train['text'].tolist()","metadata":{"execution":{"iopub.status.busy":"2024-11-06T04:55:56.100220Z","iopub.execute_input":"2024-11-06T04:55:56.101050Z","iopub.status.idle":"2024-11-06T04:55:56.106085Z","shell.execute_reply.started":"2024-11-06T04:55:56.100996Z","shell.execute_reply":"2024-11-06T04:55:56.105099Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"dev_data = weibo_dev['text'].tolist()\ndev_label = weibo_dev['label'].replace(LABELS, [0, 1]).tolist()","metadata":{"execution":{"iopub.status.busy":"2024-11-06T04:55:56.505485Z","iopub.execute_input":"2024-11-06T04:55:56.505862Z","iopub.status.idle":"2024-11-06T04:55:56.512899Z","shell.execute_reply.started":"2024-11-06T04:55:56.505826Z","shell.execute_reply":"2024-11-06T04:55:56.511973Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/358168363.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  dev_label = weibo_dev['label'].replace(LABELS, [0, 1]).tolist()\n","output_type":"stream"}]},{"cell_type":"code","source":"test_data = weibo_test['text'].tolist()\ntest_label = weibo_test['label'].replace(LABELS, [0, 1]).tolist()","metadata":{"execution":{"iopub.status.busy":"2024-11-06T04:55:56.833270Z","iopub.execute_input":"2024-11-06T04:55:56.833695Z","iopub.status.idle":"2024-11-06T04:55:56.846677Z","shell.execute_reply.started":"2024-11-06T04:55:56.833654Z","shell.execute_reply":"2024-11-06T04:55:56.845419Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/6925416.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  test_label = weibo_test['label'].replace(LABELS, [0, 1]).tolist()\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\n\nclass ClassificationDataset(Dataset):\n    def __init__(self, texts: list[str], labels: list[int], tokenizer, max_length: int):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n    \n    def __len__(self):\n        return len(self.texts)\n    \n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        label = self.labels[idx]\n        \n        encoding = self.tokenizer.encode_plus(\n            text, \n            add_special_tokens=True, \n            max_length=self.max_length, \n            return_token_type_ids=False, \n            padding=\"max_length\",\n            truncation=True, \n            return_attention_mask=True, \n            return_tensors=\"pt\"\n        )\n        \n        return {\n            \"input_ids\": encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'label': torch.tensor(label, dtype=torch.long)\n        }","metadata":{"execution":{"iopub.status.busy":"2024-11-06T04:55:57.180914Z","iopub.execute_input":"2024-11-06T04:55:57.181276Z","iopub.status.idle":"2024-11-06T04:56:00.506495Z","shell.execute_reply.started":"2024-11-06T04:55:57.181240Z","shell.execute_reply":"2024-11-06T04:56:00.505675Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from transformers import RobertaTokenizer, RobertaModel, AdamW\n\nmax_length = 128\n\ntokenizer = RobertaTokenizer.from_pretrained('roberta-base')\ntrain_dataset = ClassificationDataset(train_data, train_label, tokenizer, max_length)\ndev_dataset = ClassificationDataset(dev_data, dev_label, tokenizer, max_length)","metadata":{"execution":{"iopub.status.busy":"2024-11-06T04:56:00.507986Z","iopub.execute_input":"2024-11-06T04:56:00.508437Z","iopub.status.idle":"2024-11-06T04:56:05.316345Z","shell.execute_reply.started":"2024-11-06T04:56:00.508373Z","shell.execute_reply":"2024-11-06T04:56:05.315278Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c45c17a15eb40179feb680992a0337e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60663b64532e431fbb01767f908e97fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09430a7484cd4683ad99115b84f995f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df4e1a52c2894192a316a7328397c84a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a79273a0344496396ee255981e45043"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"batch_size = 32\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ndev_loader = DataLoader(dev_dataset, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-11-06T04:56:05.317704Z","iopub.execute_input":"2024-11-06T04:56:05.318147Z","iopub.status.idle":"2024-11-06T04:56:05.323599Z","shell.execute_reply.started":"2024-11-06T04:56:05.318113Z","shell.execute_reply":"2024-11-06T04:56:05.322266Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"test_dataset = ClassificationDataset(test_data, test_label, tokenizer, max_length)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-11-06T04:56:05.326401Z","iopub.execute_input":"2024-11-06T04:56:05.326899Z","iopub.status.idle":"2024-11-06T04:56:05.334563Z","shell.execute_reply.started":"2024-11-06T04:56:05.326849Z","shell.execute_reply":"2024-11-06T04:56:05.333610Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"## Model Preparation","metadata":{}},{"cell_type":"code","source":"num_classes = 2","metadata":{"execution":{"iopub.status.busy":"2024-11-06T04:56:05.336337Z","iopub.execute_input":"2024-11-06T04:56:05.336710Z","iopub.status.idle":"2024-11-06T04:56:05.344733Z","shell.execute_reply.started":"2024-11-06T04:56:05.336662Z","shell.execute_reply":"2024-11-06T04:56:05.343780Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"class RobertaClassifier(nn.Module):\n    def __init__(self, roberta_model, num_classes, dropout=0.1):\n        super(RobertaClassifier, self).__init__()\n        self.roberta = roberta_model\n        self.dropout = nn.Dropout(dropout)\n        self.ffn = nn.Sequential(\n            nn.Linear(768, 256),\n            nn.ReLU(),\n            nn.Linear(256, num_classes)\n        )\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n        pooled_output = outputs.pooler_output\n        x = self.dropout(pooled_output)\n        logits = self.ffn(x)\n        return logits","metadata":{"execution":{"iopub.status.busy":"2024-11-06T04:56:05.346008Z","iopub.execute_input":"2024-11-06T04:56:05.346358Z","iopub.status.idle":"2024-11-06T04:56:05.356708Z","shell.execute_reply.started":"2024-11-06T04:56:05.346320Z","shell.execute_reply":"2024-11-06T04:56:05.355850Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"roberta_model = RobertaModel.from_pretrained('roberta-base')","metadata":{"execution":{"iopub.status.busy":"2024-11-06T04:56:05.357891Z","iopub.execute_input":"2024-11-06T04:56:05.358215Z","iopub.status.idle":"2024-11-06T04:56:08.660302Z","shell.execute_reply.started":"2024-11-06T04:56:05.358178Z","shell.execute_reply":"2024-11-06T04:56:08.659540Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97499352b6c94068b1077c0d56120ca8"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"model = RobertaClassifier(roberta_model, num_classes)","metadata":{"execution":{"iopub.status.busy":"2024-11-06T04:56:08.661338Z","iopub.execute_input":"2024-11-06T04:56:08.661653Z","iopub.status.idle":"2024-11-06T04:56:08.668443Z","shell.execute_reply.started":"2024-11-06T04:56:08.661619Z","shell.execute_reply":"2024-11-06T04:56:08.667588Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"learning_rate = 2e-5\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-11-06T04:56:08.669732Z","iopub.execute_input":"2024-11-06T04:56:08.670489Z","iopub.status.idle":"2024-11-06T04:56:09.090128Z","shell.execute_reply.started":"2024-11-06T04:56:08.670445Z","shell.execute_reply":"2024-11-06T04:56:09.089201Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"RobertaClassifier(\n  (roberta): RobertaModel(\n    (embeddings): RobertaEmbeddings(\n      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n      (position_embeddings): Embedding(514, 768, padding_idx=1)\n      (token_type_embeddings): Embedding(1, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): RobertaEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): RobertaPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (ffn): Sequential(\n    (0): Linear(in_features=768, out_features=256, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=256, out_features=2, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\nimport numpy as np\nfrom tqdm import tqdm\n\ndef calculate_metrics(y_true, y_pred, y_pred_proba, num_classes):\n    if num_classes == 2:\n        metrics = {\n            'accuracy': accuracy_score(y_true, y_pred),\n            'precision': precision_score(y_true, y_pred),\n            'recall': recall_score(y_true, y_pred),\n            'f1': f1_score(y_true, y_pred)\n        }\n    else:\n        metrics = {\n            'accuracy': accuracy_score(y_true, y_pred),\n            'precision': precision_score(y_true, y_pred, average='weighted'),\n            'recall': recall_score(y_true, y_pred, average='weighted'),\n            'f1': f1_score(y_true, y_pred, average='weighted')\n        }\n    \n    # Calculate ROC-AUC score\n    if num_classes == 2:\n        metrics['roc_auc'] = roc_auc_score(y_true, y_pred_proba[:, 1])\n    else:\n        try:\n            metrics['roc_auc'] = roc_auc_score(y_true, y_pred_proba, multi_class='ovr', average='weighted')\n        except:\n            metrics['roc_auc'] = None\n            \n    return metrics","metadata":{"execution":{"iopub.status.busy":"2024-11-06T04:56:09.093941Z","iopub.execute_input":"2024-11-06T04:56:09.094259Z","iopub.status.idle":"2024-11-06T04:56:09.634480Z","shell.execute_reply.started":"2024-11-06T04:56:09.094226Z","shell.execute_reply":"2024-11-06T04:56:09.633588Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def evaluate(model, data_loader, device, num_classes):\n    model.eval()\n    all_labels = []\n    all_predictions = []\n    all_predictions_proba = []\n\n    with torch.no_grad():\n        for batch in data_loader:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['label'].to(device)\n\n            outputs = model(input_ids, attention_mask)\n            probabilities = torch.softmax(outputs, dim=1)\n            _, predicted = torch.max(outputs, 1)\n            \n            all_labels.extend(labels.cpu().numpy())\n            all_predictions.extend(predicted.cpu().numpy())\n            all_predictions_proba.extend(probabilities.cpu().numpy())\n\n    all_labels = np.array(all_labels)\n    all_predictions = np.array(all_predictions)\n    all_predictions_proba = np.array(all_predictions_proba)\n\n    return calculate_metrics(all_labels, all_predictions, all_predictions_proba, num_classes)","metadata":{"execution":{"iopub.status.busy":"2024-11-06T04:56:09.635689Z","iopub.execute_input":"2024-11-06T04:56:09.636156Z","iopub.status.idle":"2024-11-06T04:56:09.644205Z","shell.execute_reply.started":"2024-11-06T04:56:09.636121Z","shell.execute_reply":"2024-11-06T04:56:09.643272Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def train(model, train_loader, val_loader, criterion, optimizer, device, num_epochs):\n    best_val_metrics = {'f1': 0.0}\n    history = {'train': [], 'val': []}\n\n    for epoch in range(num_epochs):\n        # Training phase\n        model.train()\n        train_loss = 0.0\n        all_train_labels = []\n        all_train_predictions = []\n        all_train_predictions_proba = []\n\n        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['label'].to(device)\n\n            optimizer.zero_grad()\n            outputs = model(input_ids, attention_mask)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            train_loss += loss.item()\n            probabilities = torch.softmax(outputs, dim=1)\n            _, predicted = torch.max(outputs, 1)\n            \n            all_train_labels.extend(labels.cpu().numpy())\n            all_train_predictions.extend(predicted.cpu().numpy())\n            all_train_predictions_proba.extend(probabilities.cpu().detach().numpy())\n\n        # Calculate training metrics\n        all_train_labels = np.array(all_train_labels)\n        all_train_predictions = np.array(all_train_predictions)\n        all_train_predictions_proba = np.array(all_train_predictions_proba)\n        train_metrics = calculate_metrics(all_train_labels, all_train_predictions, \n                                       all_train_predictions_proba, num_classes)\n        \n        # Validation phase\n        val_metrics = evaluate(model, val_loader, device, num_classes)\n        \n        # Store metrics history\n        history['train'].append({\n            'loss': train_loss / len(train_loader),\n            **train_metrics\n        })\n        history['val'].append(val_metrics)\n\n        # Print epoch results\n        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n        print(\"Training Metrics:\")\n        print(f\"Loss: {train_loss/len(train_loader):.4f}\")\n        for metric, value in train_metrics.items():\n            print(f\"{metric.capitalize()}: {value:.4f}\")\n        \n        print(\"\\nValidation Metrics:\")\n        for metric, value in val_metrics.items():\n            print(f\"{metric.capitalize()}: {value:.4f}\")\n    \n    return history","metadata":{"execution":{"iopub.status.busy":"2024-11-06T04:56:09.645255Z","iopub.execute_input":"2024-11-06T04:56:09.645999Z","iopub.status.idle":"2024-11-06T04:56:09.659969Z","shell.execute_reply.started":"2024-11-06T04:56:09.645954Z","shell.execute_reply":"2024-11-06T04:56:09.659182Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"num_epochs = 5\n\noptimizer = AdamW(model.parameters(), lr=learning_rate)\ncriterion = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2024-11-06T04:56:09.660942Z","iopub.execute_input":"2024-11-06T04:56:09.661249Z","iopub.status.idle":"2024-11-06T04:56:10.276619Z","shell.execute_reply.started":"2024-11-06T04:56:09.661218Z","shell.execute_reply":"2024-11-06T04:56:10.275630Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"history = train(model, train_loader, dev_loader, criterion, optimizer, device, num_epochs)","metadata":{"execution":{"iopub.status.busy":"2024-11-06T04:56:10.277842Z","iopub.execute_input":"2024-11-06T04:56:10.278288Z","iopub.status.idle":"2024-11-06T04:59:33.385876Z","shell.execute_reply.started":"2024-11-06T04:56:10.278253Z","shell.execute_reply":"2024-11-06T04:59:33.384933Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"Epoch 1/5: 100%|██████████| 99/99 [00:42<00:00,  2.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1/5\nTraining Metrics:\nLoss: 0.6725\nAccuracy: 0.5688\nPrecision: 0.5785\nRecall: 0.4795\nF1: 0.5244\nRoc_auc: 0.6150\n\nValidation Metrics:\nAccuracy: 0.6510\nPrecision: 0.6030\nRecall: 0.8707\nF1: 0.7125\nRoc_auc: 0.7431\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/5: 100%|██████████| 99/99 [00:37<00:00,  2.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 2/5\nTraining Metrics:\nLoss: 0.6138\nAccuracy: 0.6670\nPrecision: 0.6446\nRecall: 0.7314\nF1: 0.6853\nRoc_auc: 0.7213\n\nValidation Metrics:\nAccuracy: 0.6916\nPrecision: 0.7075\nRecall: 0.6466\nF1: 0.6757\nRoc_auc: 0.7787\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/5: 100%|██████████| 99/99 [00:37<00:00,  2.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 3/5\nTraining Metrics:\nLoss: 0.5759\nAccuracy: 0.7029\nPrecision: 0.6895\nRecall: 0.7288\nF1: 0.7086\nRoc_auc: 0.7686\n\nValidation Metrics:\nAccuracy: 0.7323\nPrecision: 0.6989\nRecall: 0.8103\nF1: 0.7505\nRoc_auc: 0.8201\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/5: 100%|██████████| 99/99 [00:37<00:00,  2.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 4/5\nTraining Metrics:\nLoss: 0.5413\nAccuracy: 0.7328\nPrecision: 0.7139\nRecall: 0.7692\nF1: 0.7405\nRoc_auc: 0.8006\n\nValidation Metrics:\nAccuracy: 0.7238\nPrecision: 0.7373\nRecall: 0.6897\nF1: 0.7127\nRoc_auc: 0.8158\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/5: 100%|██████████| 99/99 [00:37<00:00,  2.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 5/5\nTraining Metrics:\nLoss: 0.4921\nAccuracy: 0.7687\nPrecision: 0.7506\nRecall: 0.7987\nF1: 0.7739\nRoc_auc: 0.8406\n\nValidation Metrics:\nAccuracy: 0.7495\nPrecision: 0.6936\nRecall: 0.8879\nF1: 0.7788\nRoc_auc: 0.8488\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\n\npd.DataFrame(history['train'])","metadata":{"execution":{"iopub.status.busy":"2024-11-06T04:59:33.387912Z","iopub.execute_input":"2024-11-06T04:59:33.388343Z","iopub.status.idle":"2024-11-06T04:59:33.400933Z","shell.execute_reply.started":"2024-11-06T04:59:33.388287Z","shell.execute_reply":"2024-11-06T04:59:33.400056Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"       loss  accuracy  precision    recall        f1   roc_auc\n0  0.672523  0.568796   0.578500  0.479487  0.524360  0.614958\n1  0.613833  0.666984   0.644633  0.731410  0.685285  0.721261\n2  0.575922  0.702892   0.689509  0.728846  0.708632  0.768639\n3  0.541324  0.732761   0.713861  0.769231  0.740512  0.800640\n4  0.492106  0.768669   0.750602  0.798718  0.773913  0.840563","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>loss</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n      <th>roc_auc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.672523</td>\n      <td>0.568796</td>\n      <td>0.578500</td>\n      <td>0.479487</td>\n      <td>0.524360</td>\n      <td>0.614958</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.613833</td>\n      <td>0.666984</td>\n      <td>0.644633</td>\n      <td>0.731410</td>\n      <td>0.685285</td>\n      <td>0.721261</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.575922</td>\n      <td>0.702892</td>\n      <td>0.689509</td>\n      <td>0.728846</td>\n      <td>0.708632</td>\n      <td>0.768639</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.541324</td>\n      <td>0.732761</td>\n      <td>0.713861</td>\n      <td>0.769231</td>\n      <td>0.740512</td>\n      <td>0.800640</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.492106</td>\n      <td>0.768669</td>\n      <td>0.750602</td>\n      <td>0.798718</td>\n      <td>0.773913</td>\n      <td>0.840563</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"pd.DataFrame(history['val'])","metadata":{"execution":{"iopub.status.busy":"2024-11-06T04:59:33.402029Z","iopub.execute_input":"2024-11-06T04:59:33.402323Z","iopub.status.idle":"2024-11-06T04:59:33.420115Z","shell.execute_reply.started":"2024-11-06T04:59:33.402290Z","shell.execute_reply":"2024-11-06T04:59:33.419202Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"   accuracy  precision    recall        f1   roc_auc\n0  0.650964   0.602985  0.870690  0.712522  0.743122\n1  0.691649   0.707547  0.646552  0.675676  0.778687\n2  0.732334   0.698885  0.810345  0.750499  0.820084\n3  0.723769   0.737327  0.689655  0.712695  0.815756\n4  0.749465   0.693603  0.887931  0.778828  0.848826","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n      <th>roc_auc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.650964</td>\n      <td>0.602985</td>\n      <td>0.870690</td>\n      <td>0.712522</td>\n      <td>0.743122</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.691649</td>\n      <td>0.707547</td>\n      <td>0.646552</td>\n      <td>0.675676</td>\n      <td>0.778687</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.732334</td>\n      <td>0.698885</td>\n      <td>0.810345</td>\n      <td>0.750499</td>\n      <td>0.820084</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.723769</td>\n      <td>0.737327</td>\n      <td>0.689655</td>\n      <td>0.712695</td>\n      <td>0.815756</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.749465</td>\n      <td>0.693603</td>\n      <td>0.887931</td>\n      <td>0.778828</td>\n      <td>0.848826</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"evaluate(model, test_loader, device, num_classes)","metadata":{"execution":{"iopub.status.busy":"2024-11-06T04:59:33.421035Z","iopub.execute_input":"2024-11-06T04:59:33.421309Z","iopub.status.idle":"2024-11-06T04:59:38.923689Z","shell.execute_reply.started":"2024-11-06T04:59:33.421278Z","shell.execute_reply":"2024-11-06T04:59:38.922664Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"{'accuracy': 0.7311725452812202,\n 'precision': 0.6853582554517134,\n 'recall': 0.8461538461538461,\n 'f1': 0.757314974182444,\n 'roc_auc': 0.8217682128835249}"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}