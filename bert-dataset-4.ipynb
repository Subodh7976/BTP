{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9820887,"sourceType":"datasetVersion","datasetId":6021774}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Data Ingestion","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# column_names = ['id', 'text', 'label']\nconstraint_train = pd.read_csv(\"/kaggle/input/dataset-4/constraint_train.csv\")\nconstraint_test = pd.read_csv(\"/kaggle/input/dataset-4/constraint_test.csv\")\nconstraint_dev = pd.read_csv(\"/kaggle/input/dataset-4/constraint_dev.csv\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-06T13:05:09.224376Z","iopub.execute_input":"2024-11-06T13:05:09.225236Z","iopub.status.idle":"2024-11-06T13:05:09.650271Z","shell.execute_reply.started":"2024-11-06T13:05:09.225187Z","shell.execute_reply":"2024-11-06T13:05:09.649500Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"constraint_train.shape, constraint_test.shape, constraint_dev.shape","metadata":{"execution":{"iopub.status.busy":"2024-11-06T13:05:09.651668Z","iopub.execute_input":"2024-11-06T13:05:09.651961Z","iopub.status.idle":"2024-11-06T13:05:09.659003Z","shell.execute_reply.started":"2024-11-06T13:05:09.651929Z","shell.execute_reply":"2024-11-06T13:05:09.658158Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"((4494, 4), (963, 4), (963, 4))"},"metadata":{}}]},{"cell_type":"markdown","source":"## Data Preparation","metadata":{}},{"cell_type":"code","source":"LABELS = constraint_train['label'].unique().tolist()\ntrain_label = constraint_train['label'].replace(LABELS, [0, 1]).tolist()","metadata":{"execution":{"iopub.status.busy":"2024-11-06T13:05:32.575829Z","iopub.execute_input":"2024-11-06T13:05:32.576484Z","iopub.status.idle":"2024-11-06T13:05:32.586388Z","shell.execute_reply.started":"2024-11-06T13:05:32.576422Z","shell.execute_reply":"2024-11-06T13:05:32.585393Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/1124859992.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  train_label = constraint_train['label'].replace(LABELS, [0, 1]).tolist()\n","output_type":"stream"}]},{"cell_type":"code","source":"train_data = constraint_train['tweet'].tolist()","metadata":{"execution":{"iopub.status.busy":"2024-11-06T13:06:29.608890Z","iopub.execute_input":"2024-11-06T13:06:29.609254Z","iopub.status.idle":"2024-11-06T13:06:29.614012Z","shell.execute_reply.started":"2024-11-06T13:06:29.609218Z","shell.execute_reply":"2024-11-06T13:06:29.613039Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"dev_data = constraint_dev['tweet'].tolist()\ndev_label = constraint_dev['label'].replace(LABELS, [0, 1]).tolist()","metadata":{"execution":{"iopub.status.busy":"2024-11-06T13:06:37.289212Z","iopub.execute_input":"2024-11-06T13:06:37.289856Z","iopub.status.idle":"2024-11-06T13:06:37.297130Z","shell.execute_reply.started":"2024-11-06T13:06:37.289815Z","shell.execute_reply":"2024-11-06T13:06:37.296304Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/2472027419.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  dev_label = constraint_dev['label'].replace(LABELS, [0, 1]).tolist()\n","output_type":"stream"}]},{"cell_type":"code","source":"test_data = constraint_test['tweet'].tolist()\ntest_label = constraint_test['label'].replace(LABELS, [0, 1]).tolist()","metadata":{"execution":{"iopub.status.busy":"2024-11-06T13:06:42.417559Z","iopub.execute_input":"2024-11-06T13:06:42.417931Z","iopub.status.idle":"2024-11-06T13:06:42.425255Z","shell.execute_reply.started":"2024-11-06T13:06:42.417895Z","shell.execute_reply":"2024-11-06T13:06:42.424294Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/1887347934.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  test_label = constraint_test['label'].replace(LABELS, [0, 1]).tolist()\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\n\nclass ClassificationDataset(Dataset):\n    def __init__(self, texts: list[str], labels: list[int], tokenizer, max_length: int):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n    \n    def __len__(self):\n        return len(self.texts)\n    \n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        label = self.labels[idx]\n        \n        encoding = self.tokenizer.encode_plus(\n            text, \n            add_special_tokens=True, \n            max_length=self.max_length, \n            return_token_type_ids=False, \n            padding=\"max_length\",\n            truncation=True, \n            return_attention_mask=True, \n            return_tensors=\"pt\"\n        )\n        \n        return {\n            \"input_ids\": encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'label': torch.tensor(label, dtype=torch.long)\n        }","metadata":{"execution":{"iopub.status.busy":"2024-11-06T13:06:47.222890Z","iopub.execute_input":"2024-11-06T13:06:47.223597Z","iopub.status.idle":"2024-11-06T13:06:50.549994Z","shell.execute_reply.started":"2024-11-06T13:06:47.223558Z","shell.execute_reply":"2024-11-06T13:06:50.549206Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from transformers import BertTokenizer, BertModel, AdamW\n\nmax_length = 128\n\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\ntrain_dataset = ClassificationDataset(train_data, train_label, tokenizer, max_length)\ndev_dataset = ClassificationDataset(dev_data, dev_label, tokenizer, max_length)","metadata":{"execution":{"iopub.status.busy":"2024-11-06T13:06:52.650304Z","iopub.execute_input":"2024-11-06T13:06:52.651267Z","iopub.status.idle":"2024-11-06T13:06:56.479354Z","shell.execute_reply.started":"2024-11-06T13:06:52.651227Z","shell.execute_reply":"2024-11-06T13:06:56.478376Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87070bb9916a4773a9622997a46995ef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"808f4fa899aa41a887eaf99164788e8f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"521f89224c914d4cb74fdef7d827e0f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9122bdf353784961a5119f4570c40d17"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"batch_size = 32\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ndev_loader = DataLoader(dev_dataset, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-11-06T13:06:56.480908Z","iopub.execute_input":"2024-11-06T13:06:56.481337Z","iopub.status.idle":"2024-11-06T13:06:56.486248Z","shell.execute_reply.started":"2024-11-06T13:06:56.481303Z","shell.execute_reply":"2024-11-06T13:06:56.485354Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"test_dataset = ClassificationDataset(test_data, test_label, tokenizer, max_length)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-11-06T13:06:59.747408Z","iopub.execute_input":"2024-11-06T13:06:59.748284Z","iopub.status.idle":"2024-11-06T13:06:59.752386Z","shell.execute_reply.started":"2024-11-06T13:06:59.748245Z","shell.execute_reply":"2024-11-06T13:06:59.751521Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## Model Preparation","metadata":{}},{"cell_type":"code","source":"num_classes = 2","metadata":{"execution":{"iopub.status.busy":"2024-11-06T13:07:05.655123Z","iopub.execute_input":"2024-11-06T13:07:05.656001Z","iopub.status.idle":"2024-11-06T13:07:05.659906Z","shell.execute_reply.started":"2024-11-06T13:07:05.655959Z","shell.execute_reply":"2024-11-06T13:07:05.659128Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"class BERTClassifier(nn.Module):\n    def __init__(self, bert_model, num_classes, dropout=0.1):\n        super(BERTClassifier, self).__init__()\n        self.bert = bert_model\n        self.dropout = nn.Dropout(dropout)\n        self.ffn = nn.Sequential(\n            nn.Linear(768, 256),\n            nn.ReLU(),\n            nn.Linear(256, num_classes)\n        )\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        pooled_output = outputs.pooler_output\n        x = self.dropout(pooled_output)\n        logits = self.ffn(x)\n        return logits","metadata":{"execution":{"iopub.status.busy":"2024-11-06T13:07:09.040921Z","iopub.execute_input":"2024-11-06T13:07:09.041627Z","iopub.status.idle":"2024-11-06T13:07:09.048296Z","shell.execute_reply.started":"2024-11-06T13:07:09.041588Z","shell.execute_reply":"2024-11-06T13:07:09.047354Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"bert_model = BertModel.from_pretrained('bert-base-uncased')","metadata":{"execution":{"iopub.status.busy":"2024-11-06T13:07:09.954128Z","iopub.execute_input":"2024-11-06T13:07:09.955004Z","iopub.status.idle":"2024-11-06T13:07:12.460115Z","shell.execute_reply.started":"2024-11-06T13:07:09.954951Z","shell.execute_reply":"2024-11-06T13:07:12.459235Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87f14640ab084857bedca63c5d1e0431"}},"metadata":{}},{"name":"stderr","text":"A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","output_type":"stream"}]},{"cell_type":"code","source":"model = BERTClassifier(bert_model, num_classes)","metadata":{"execution":{"iopub.status.busy":"2024-11-06T13:07:16.329795Z","iopub.execute_input":"2024-11-06T13:07:16.330187Z","iopub.status.idle":"2024-11-06T13:07:16.338929Z","shell.execute_reply.started":"2024-11-06T13:07:16.330151Z","shell.execute_reply":"2024-11-06T13:07:16.338090Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"learning_rate = 2e-5\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-11-06T13:07:18.559279Z","iopub.execute_input":"2024-11-06T13:07:18.559674Z","iopub.status.idle":"2024-11-06T13:07:18.892307Z","shell.execute_reply.started":"2024-11-06T13:07:18.559636Z","shell.execute_reply":"2024-11-06T13:07:18.891358Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"BERTClassifier(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (ffn): Sequential(\n    (0): Linear(in_features=768, out_features=256, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=256, out_features=2, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\nimport numpy as np\nfrom tqdm import tqdm\n\ndef calculate_metrics(y_true, y_pred, y_pred_proba, num_classes):\n    if num_classes == 2:\n        metrics = {\n            'accuracy': accuracy_score(y_true, y_pred),\n            'precision': precision_score(y_true, y_pred),\n            'recall': recall_score(y_true, y_pred),\n            'f1': f1_score(y_true, y_pred)\n        }\n    else:\n        metrics = {\n            'accuracy': accuracy_score(y_true, y_pred),\n            'precision': precision_score(y_true, y_pred, average='weighted'),\n            'recall': recall_score(y_true, y_pred, average='weighted'),\n            'f1': f1_score(y_true, y_pred, average='weighted')\n        }\n    \n    # Calculate ROC-AUC score\n    if num_classes == 2:\n        metrics['roc_auc'] = roc_auc_score(y_true, y_pred_proba[:, 1])\n    else:\n        try:\n            metrics['roc_auc'] = roc_auc_score(y_true, y_pred_proba, multi_class='ovr', average='weighted')\n        except:\n            metrics['roc_auc'] = None\n            \n    return metrics","metadata":{"execution":{"iopub.status.busy":"2024-11-06T13:07:42.228296Z","iopub.execute_input":"2024-11-06T13:07:42.229332Z","iopub.status.idle":"2024-11-06T13:07:42.845235Z","shell.execute_reply.started":"2024-11-06T13:07:42.229288Z","shell.execute_reply":"2024-11-06T13:07:42.844199Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def evaluate(model, data_loader, device, num_classes):\n    model.eval()\n    all_labels = []\n    all_predictions = []\n    all_predictions_proba = []\n\n    with torch.no_grad():\n        for batch in data_loader:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['label'].to(device)\n\n            outputs = model(input_ids, attention_mask)\n            probabilities = torch.softmax(outputs, dim=1)\n            _, predicted = torch.max(outputs, 1)\n            \n            all_labels.extend(labels.cpu().numpy())\n            all_predictions.extend(predicted.cpu().numpy())\n            all_predictions_proba.extend(probabilities.cpu().numpy())\n\n    all_labels = np.array(all_labels)\n    all_predictions = np.array(all_predictions)\n    all_predictions_proba = np.array(all_predictions_proba)\n\n    return calculate_metrics(all_labels, all_predictions, all_predictions_proba, num_classes)","metadata":{"execution":{"iopub.status.busy":"2024-11-06T13:07:46.513399Z","iopub.execute_input":"2024-11-06T13:07:46.514345Z","iopub.status.idle":"2024-11-06T13:07:46.522925Z","shell.execute_reply.started":"2024-11-06T13:07:46.514304Z","shell.execute_reply":"2024-11-06T13:07:46.521959Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def train(model, train_loader, val_loader, criterion, optimizer, device, num_epochs):\n    best_val_metrics = {'f1': 0.0}\n    history = {'train': [], 'val': []}\n\n    for epoch in range(num_epochs):\n        # Training phase\n        model.train()\n        train_loss = 0.0\n        all_train_labels = []\n        all_train_predictions = []\n        all_train_predictions_proba = []\n\n        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['label'].to(device)\n\n            optimizer.zero_grad()\n            outputs = model(input_ids, attention_mask)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            train_loss += loss.item()\n            probabilities = torch.softmax(outputs, dim=1)\n            _, predicted = torch.max(outputs, 1)\n            \n            all_train_labels.extend(labels.cpu().numpy())\n            all_train_predictions.extend(predicted.cpu().numpy())\n            all_train_predictions_proba.extend(probabilities.cpu().detach().numpy())\n\n        # Calculate training metrics\n        all_train_labels = np.array(all_train_labels)\n        all_train_predictions = np.array(all_train_predictions)\n        all_train_predictions_proba = np.array(all_train_predictions_proba)\n        train_metrics = calculate_metrics(all_train_labels, all_train_predictions, \n                                       all_train_predictions_proba, num_classes)\n        \n        # Validation phase\n        val_metrics = evaluate(model, val_loader, device, num_classes)\n        \n        # Store metrics history\n        history['train'].append({\n            'loss': train_loss / len(train_loader),\n            **train_metrics\n        })\n        history['val'].append(val_metrics)\n\n        # Print epoch results\n        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n        print(\"Training Metrics:\")\n        print(f\"Loss: {train_loss/len(train_loader):.4f}\")\n        for metric, value in train_metrics.items():\n            print(f\"{metric.capitalize()}: {value:.4f}\")\n        \n        print(\"\\nValidation Metrics:\")\n        for metric, value in val_metrics.items():\n            print(f\"{metric.capitalize()}: {value:.4f}\")\n    \n    return history","metadata":{"execution":{"iopub.status.busy":"2024-11-06T13:07:47.235251Z","iopub.execute_input":"2024-11-06T13:07:47.235642Z","iopub.status.idle":"2024-11-06T13:07:47.248519Z","shell.execute_reply.started":"2024-11-06T13:07:47.235605Z","shell.execute_reply":"2024-11-06T13:07:47.247441Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"num_epochs = 5\n\noptimizer = AdamW(model.parameters(), lr=learning_rate)\ncriterion = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2024-11-06T13:08:01.974253Z","iopub.execute_input":"2024-11-06T13:08:01.974637Z","iopub.status.idle":"2024-11-06T13:08:02.605804Z","shell.execute_reply.started":"2024-11-06T13:08:01.974601Z","shell.execute_reply":"2024-11-06T13:08:02.604990Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"history = train(model, train_loader, dev_loader, criterion, optimizer, device, num_epochs)","metadata":{"execution":{"iopub.status.busy":"2024-11-06T13:08:03.817562Z","iopub.execute_input":"2024-11-06T13:08:03.818588Z","iopub.status.idle":"2024-11-06T13:13:10.450629Z","shell.execute_reply.started":"2024-11-06T13:08:03.818545Z","shell.execute_reply":"2024-11-06T13:13:10.449643Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"Epoch 1/5: 100%|██████████| 141/141 [00:56<00:00,  2.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1/5\nTraining Metrics:\nLoss: 0.2743\nAccuracy: 0.9072\nPrecision: 0.9114\nRecall: 0.8942\nF1: 0.9027\nRoc_auc: 0.9601\n\nValidation Metrics:\nAccuracy: 0.9637\nPrecision: 0.9610\nRecall: 0.9588\nF1: 0.9599\nRoc_auc: 0.9926\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/5: 100%|██████████| 141/141 [00:56<00:00,  2.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 2/5\nTraining Metrics:\nLoss: 0.0846\nAccuracy: 0.9755\nPrecision: 0.9790\nRecall: 0.9700\nF1: 0.9745\nRoc_auc: 0.9940\n\nValidation Metrics:\nAccuracy: 0.9595\nPrecision: 0.9364\nRecall: 0.9771\nF1: 0.9563\nRoc_auc: 0.9952\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/5: 100%|██████████| 141/141 [00:56<00:00,  2.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 3/5\nTraining Metrics:\nLoss: 0.0353\nAccuracy: 0.9900\nPrecision: 0.9903\nRecall: 0.9889\nF1: 0.9896\nRoc_auc: 0.9984\n\nValidation Metrics:\nAccuracy: 0.9740\nPrecision: 0.9813\nRecall: 0.9611\nF1: 0.9711\nRoc_auc: 0.9919\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/5: 100%|██████████| 141/141 [00:56<00:00,  2.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 4/5\nTraining Metrics:\nLoss: 0.0273\nAccuracy: 0.9915\nPrecision: 0.9930\nRecall: 0.9894\nF1: 0.9912\nRoc_auc: 0.9989\n\nValidation Metrics:\nAccuracy: 0.9637\nPrecision: 0.9427\nRecall: 0.9794\nF1: 0.9607\nRoc_auc: 0.9946\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/5: 100%|██████████| 141/141 [00:56<00:00,  2.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 5/5\nTraining Metrics:\nLoss: 0.0251\nAccuracy: 0.9920\nPrecision: 0.9912\nRecall: 0.9921\nF1: 0.9917\nRoc_auc: 0.9996\n\nValidation Metrics:\nAccuracy: 0.9564\nPrecision: 0.9925\nRecall: 0.9108\nF1: 0.9499\nRoc_auc: 0.9921\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\n\npd.DataFrame(history['train'])","metadata":{"execution":{"iopub.status.busy":"2024-11-06T13:13:10.452907Z","iopub.execute_input":"2024-11-06T13:13:10.453383Z","iopub.status.idle":"2024-11-06T13:13:10.470507Z","shell.execute_reply.started":"2024-11-06T13:13:10.453337Z","shell.execute_reply":"2024-11-06T13:13:10.469631Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"       loss  accuracy  precision    recall        f1   roc_auc\n0  0.274277  0.907210   0.911446  0.894177  0.902729  0.960133\n1  0.084637  0.975523   0.979011  0.969963  0.974466  0.993954\n2  0.035306  0.989987   0.990282  0.988909  0.989595  0.998400\n3  0.027290  0.991544   0.993043  0.989372  0.991204  0.998928\n4  0.025055  0.991989   0.991228  0.992144  0.991686  0.999574","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>loss</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n      <th>roc_auc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.274277</td>\n      <td>0.907210</td>\n      <td>0.911446</td>\n      <td>0.894177</td>\n      <td>0.902729</td>\n      <td>0.960133</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.084637</td>\n      <td>0.975523</td>\n      <td>0.979011</td>\n      <td>0.969963</td>\n      <td>0.974466</td>\n      <td>0.993954</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.035306</td>\n      <td>0.989987</td>\n      <td>0.990282</td>\n      <td>0.988909</td>\n      <td>0.989595</td>\n      <td>0.998400</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.027290</td>\n      <td>0.991544</td>\n      <td>0.993043</td>\n      <td>0.989372</td>\n      <td>0.991204</td>\n      <td>0.998928</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.025055</td>\n      <td>0.991989</td>\n      <td>0.991228</td>\n      <td>0.992144</td>\n      <td>0.991686</td>\n      <td>0.999574</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"pd.DataFrame(history['val'])","metadata":{"execution":{"iopub.status.busy":"2024-11-06T13:13:10.471639Z","iopub.execute_input":"2024-11-06T13:13:10.471947Z","iopub.status.idle":"2024-11-06T13:13:10.484518Z","shell.execute_reply.started":"2024-11-06T13:13:10.471913Z","shell.execute_reply":"2024-11-06T13:13:10.483597Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"   accuracy  precision    recall        f1   roc_auc\n0  0.963655   0.961009  0.958810  0.959908  0.992583\n1  0.959502   0.936404  0.977117  0.956327  0.995215\n2  0.974039   0.981308  0.961098  0.971098  0.991943\n3  0.963655   0.942731  0.979405  0.960718  0.994597\n4  0.956386   0.992519  0.910755  0.949881  0.992052","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n      <th>roc_auc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.963655</td>\n      <td>0.961009</td>\n      <td>0.958810</td>\n      <td>0.959908</td>\n      <td>0.992583</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.959502</td>\n      <td>0.936404</td>\n      <td>0.977117</td>\n      <td>0.956327</td>\n      <td>0.995215</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.974039</td>\n      <td>0.981308</td>\n      <td>0.961098</td>\n      <td>0.971098</td>\n      <td>0.991943</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.963655</td>\n      <td>0.942731</td>\n      <td>0.979405</td>\n      <td>0.960718</td>\n      <td>0.994597</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.956386</td>\n      <td>0.992519</td>\n      <td>0.910755</td>\n      <td>0.949881</td>\n      <td>0.992052</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"evaluate(model, test_loader, device, num_classes)","metadata":{"execution":{"iopub.status.busy":"2024-11-06T13:13:10.486350Z","iopub.execute_input":"2024-11-06T13:13:10.486648Z","iopub.status.idle":"2024-11-06T13:13:15.114620Z","shell.execute_reply.started":"2024-11-06T13:13:10.486617Z","shell.execute_reply":"2024-11-06T13:13:15.113699Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"{'accuracy': 0.9511941848390446,\n 'precision': 0.992822966507177,\n 'recall': 0.9041394335511983,\n 'f1': 0.9464082098061575,\n 'roc_auc': 0.9938271604938271}"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}